import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import (
    RGCNConv, FastRGCNConv, GCNConv, GATConv, RGATConv
)



class ESAFastBotRGCN(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=1, embedding_dimension=128, dropout=0.3):
        super(ESAFastBotRGCN, self).__init__()
        self.dropout = dropout

        # å°†æ¯ä¸€ç±»ç‰¹å¾çº¿æ€§å‹ç¼©ä¸º embedding_dimension/5 ç»´åº¦ï¼Œå…±äº”ç±»ï¼ˆdes, tweet, num_prop, cat_prop, new_featureï¼‰
        per_feature_dim = embedding_dimension // 5

        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, per_feature_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, 28),
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, per_feature_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, per_feature_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(
            nn.Linear(new_feature_size, per_feature_dim),
            nn.LeakyReLU()
        )

        self.linear_relu_input = nn.Sequential(
            nn.Linear(embedding_dimension, embedding_dimension),
            nn.LeakyReLU()
        )

        self.rgcn1 = FastRGCNConv(embedding_dimension, embedding_dimension, num_relations=2)
        self.rgcn2 = FastRGCNConv(embedding_dimension, embedding_dimension, num_relations=2)

        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(embedding_dimension, embedding_dimension),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(embedding_dimension, 2)

    def forward(self, des, tweet, num_prop, cat_prop, new_feature, edge_index, edge_type):
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)

        x = torch.cat((d, t, n, c, nf), dim=1)
        x = self.linear_relu_input(x)

        x = self.rgcn1(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn2(x, edge_index, edge_type)

        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)
        return x






class ESABotRGCN(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=2, dropout=0.3):
        super(ESABotRGCN, self).__init__()
        self.dropout = dropout

        # ğŸ‘‰ å„è‡ªå‹ç¼©ç»´åº¦æŒ‰ä½ çš„éœ€æ±‚è®¾ç½®
        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, 25),  # 32ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, 28),  # 52ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, 25),  # 12ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, 25),  # 20ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(  # æ–°å¢çš„ç‰¹å¾ 12ç»´
            nn.Linear(new_feature_size, 25),  # 12ç»´åº¦
            nn.LeakyReLU()
        )
        
        # ğŸ‘‡ æ€»ç»´åº¦æ”¹æˆ 128ï¼ˆ32 + 52 + 12 + 20 + 12ï¼‰
        self.linear_relu_input = nn.Sequential(
            nn.Linear(128, 128),  # é‡æ–°è°ƒæ•´æ€»è¾“å…¥ç»´åº¦ä¸º128
            nn.LeakyReLU()
        )

        self.rgcn = RGCNConv(128, 128, num_relations=2)

        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(128, 128),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(128, 2)

    def forward(self, des, tweet, num_prop, cat_prop, new_feature, edge_index, edge_type):
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)  # å¤„ç†æ–°ç‰¹å¾

        # æ‹¼æ¥æ—¶åŠ å…¥æ–°ç‰¹å¾ï¼Œæ³¨æ„æ–°çš„ç‰¹å¾ç»´åº¦
        x = torch.cat((d, t, n, c, nf), dim=1)
        x = self.linear_relu_input(x)
        x = self.rgcn(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn(x, edge_index, edge_type)
        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)
        return x


class ESACustomBotRGCN(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=1,
                 des_dim=28, tweet_dim=36, num_dim=12, cat_dim=40, new_dim=12, dropout=0.3):
        super(ESACustomBotRGCN, self).__init__()
        self.dropout = dropout

        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, des_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, tweet_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, num_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, cat_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(
            nn.Linear(new_feature_size, new_dim),
            nn.LeakyReLU()
        )

        total_dim = des_dim + tweet_dim + num_dim + cat_dim + new_dim
        self.linear_relu_input = nn.Sequential(
            nn.Linear(total_dim, total_dim),
            nn.LeakyReLU()
        )

        self.rgcn1 = RGCNConv(total_dim, total_dim, num_relations=2)
        self.rgcn2 = RGCNConv(total_dim, total_dim, num_relations=2)

        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(total_dim, total_dim),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(total_dim, 2)

    def forward(self, des, tweet, num_prop, cat_prop, new_feature, edge_index, edge_type):
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)

        x = torch.cat((d, t, n, c, nf), dim=1)
        x = self.linear_relu_input(x)
        x = self.rgcn1(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn2(x, edge_index, edge_type)
        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)
        return x







class ESAFeatureAttention(nn.Module):
    def __init__(self, num_features):
        super(ESAFeatureAttention, self).__init__()
        self.attn_weights = nn.Parameter(torch.Tensor(num_features, 1))
        nn.init.xavier_uniform_(self.attn_weights)

    # def forward(self, features):
    #     # features: list of [batch, dim] tensors
    #     stacked = torch.stack(features, dim=0)  # [num_features, batch, dim]
    #     weights = torch.softmax(self.attn_weights, dim=0)  # [num_features, 1]
    #     weighted = weights * stacked
    #     fused = torch.sum(weighted, dim=0)  # [batch, dim]
    #     return fused
    def forward(self, features):
        # features: list of [batch_size, dim] tensors
        stacked = torch.stack(features, dim=0)  # [num_features, batch_size, dim]
        weights = torch.softmax(self.attn_weights, dim=0).unsqueeze(1)  # [num_features, 1, 1]
        weighted = weights * stacked  # âœ… å¹¿æ’­æˆåŠŸ
        fused = torch.sum(weighted, dim=0)  # [batch_size, dim]
        return fused

    def get_attention_weights(self):
        return torch.softmax(self.attn_weights.data, dim=0).squeeze()


class ESABotRGCNWithAttention(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=3, new_feature_size=1,
                 common_dim=64, embedding_dimension=128, dropout=0.3):
        super(ESABotRGCNWithAttention, self).__init__()
        self.dropout = dropout

        # ç‰¹å¾ç¼–ç ï¼ˆå…ˆå‹ç¼©æˆç»Ÿä¸€ç»´åº¦ common_dimï¼‰
        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, common_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, common_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, common_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, common_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(
            nn.Linear(new_feature_size, common_dim),
            nn.LeakyReLU()
        )

        # æ³¨æ„åŠ›èåˆå±‚
        self.feature_attention = ESAFeatureAttention(num_features=5)

        # å›¾ç¥ç»ç½‘ç»œéƒ¨åˆ†
        self.linear_relu_input = nn.Sequential(
            nn.Linear(common_dim, embedding_dimension),
            nn.LeakyReLU()
        )
        self.rgcn = RGCNConv(embedding_dimension, embedding_dimension, num_relations=2)
        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(embedding_dimension, embedding_dimension),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(embedding_dimension, 2)

    def forward(self, des, tweet, num_prop, cat_prop, new_feature, edge_index, edge_type):
        # å„ç±»ç‰¹å¾å‹ç¼©
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)

        # æ³¨æ„åŠ›èåˆ
        fused = self.feature_attention([d, t, n, c, nf])  # [batch, common_dim]

        # GNN åç»­å¤„ç†
        x = self.linear_relu_input(fused)
        x = self.rgcn(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn(x, edge_index, edge_type)
        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)
        return x

    def print_attention_weights(self):
        weights = self.feature_attention.get_attention_weights()
        print("\nğŸ§  Attention Weights (Feature Importance):")
        for name, w in zip(["Description", "Tweets", "NumProp", "CatProp", "NewFeature"], weights):
            print(f"  {name}: {w.item():.4f}")




class ESABotNoGCN(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=1, dropout=0.3):
        super(ESABotNoGCN, self).__init__()
        self.dropout = dropout

        # ğŸ‘‰ å„è‡ªå‹ç¼©ç»´åº¦æŒ‰ä½ çš„éœ€æ±‚è®¾ç½®
        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, 28),  # 32ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, 36),  # 52ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, 12),  # 12ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, 40),  # 20ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(  # æ–°å¢çš„ç‰¹å¾ 12ç»´
            nn.Linear(new_feature_size, 12),  # 12ç»´åº¦
            nn.LeakyReLU()
        )
        
        # ğŸ‘‡ æ€»ç»´åº¦æ”¹æˆ 128ï¼ˆ32 + 52 + 12 + 20 + 12ï¼‰
        self.linear_relu_input = nn.Sequential(
            nn.Linear(128, 128),  # é‡æ–°è°ƒæ•´æ€»è¾“å…¥ç»´åº¦ä¸º128
            nn.LeakyReLU()
        )

        # noGCN éƒ¨åˆ†ï¼šæˆ‘ä»¬ç”¨ä¸€ä¸ªå…¨è¿æ¥å±‚æ¥ä»£æ›¿RGCN
        self.fc1 = nn.Linear(128, 128)  # ç”¨å…¨è¿æ¥å±‚ä»£æ›¿å›¾å·ç§¯å±‚
        self.fc2 = nn.Linear(128, 128)  # ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚
        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(128, 128),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(128, 2)

    def forward(self, des, tweet, num_prop, cat_prop, new_feature):
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)  # å¤„ç†æ–°ç‰¹å¾

        # æ‹¼æ¥æ—¶åŠ å…¥æ–°ç‰¹å¾ï¼Œæ³¨æ„æ–°çš„ç‰¹å¾ç»´åº¦
        x = torch.cat((d, t, n, c, nf), dim=1)
        x = self.linear_relu_input(x)

        # ç”¨å…¨è¿æ¥å±‚æ›¿ä»£RGCNå±‚
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.fc1(x)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.fc2(x)
        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)

        return x









import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GATConv  # å¼•å…¥ GATConv å±‚
class ESABotGAT(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=1, dropout=0.3, num_heads=4):
        super(ESABotGAT, self).__init__()
        self.dropout = dropout

        # ğŸ‘‰ å„è‡ªå‹ç¼©ç»´åº¦æŒ‰ä½ çš„éœ€æ±‚è®¾ç½®
        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, 28),  # 32ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, 36),  # 52ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, 12),  # 12ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, 40),  # 20ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(  # æ–°å¢çš„ç‰¹å¾ 12ç»´
            nn.Linear(new_feature_size, 12),  # 12ç»´åº¦
            nn.LeakyReLU()
        )

        # ğŸ‘‡ æ€»ç»´åº¦æ”¹æˆ 128ï¼ˆ32 + 52 + 12 + 20 + 12ï¼‰
        self.linear_relu_input = nn.Sequential(
            nn.Linear(128, 128),  # é‡æ–°è°ƒæ•´æ€»è¾“å…¥ç»´åº¦ä¸º128
            nn.LeakyReLU()
        )

        # ä½¿ç”¨ GATConv æ›¿ä»£ RGCNConv
        self.gat1 = GATConv(128, 128, heads=num_heads, dropout=self.dropout)  # æ³¨æ„è¿™é‡Œ
        self.gat2 = GATConv(128 * num_heads, 128, dropout=self.dropout)  # ä¿®æ”¹ä¸º num_heads * 128

        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(128, 128),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(128, 2)

    def forward(self, des, tweet, num_prop, cat_prop, new_feature, edge_index):
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)  # å¤„ç†æ–°ç‰¹å¾

        # æ‹¼æ¥æ—¶åŠ å…¥æ–°ç‰¹å¾ï¼Œæ³¨æ„æ–°çš„ç‰¹å¾ç»´åº¦
        x = torch.cat((d, t, n, c, nf), dim=1)  # æ‹¼æ¥æ“ä½œ
        x = self.linear_relu_input(x)

        # ä½¿ç”¨ GATConv è¿›è¡Œä¿¡æ¯èšåˆ
        x = self.gat1(x, edge_index)  # ç¬¬ä¸€å±‚ GAT
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.gat2(x, edge_index)  # ç¬¬äºŒå±‚ GAT

        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)
        return x










class ESABotGCN(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=1, embedding_dimension=128, dropout=0.3):
        super(ESABotGCN, self).__init__()
        self.dropout = dropout

        # å„è‡ªå‹ç¼©ç»´åº¦æŒ‰æ‚¨çš„è¦æ±‚è®¾ç½®
        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, 28),  # å°† description ç‰¹å¾å‹ç¼©åˆ° 28 ç»´
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, 36),  # å°† tweet ç‰¹å¾å‹ç¼©åˆ° 36 ç»´
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, 12),  # å°† num_prop ç‰¹å¾å‹ç¼©åˆ° 12 ç»´
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, 40),  # å°† cat_prop ç‰¹å¾å‹ç¼©åˆ° 40 ç»´
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(  # å°†æ–°ç‰¹å¾å‹ç¼©åˆ° 12 ç»´
            nn.Linear(new_feature_size, 12),  # 12 ç»´åº¦
            nn.LeakyReLU()
        )

        # æ‹¼æ¥ç‰¹å¾åè¾“å…¥çš„ç»´åº¦ä¸º 128
        self.linear_relu_input = nn.Sequential(
            nn.Linear(128, 128),  # å°†æ‹¼æ¥åçš„ç‰¹å¾ç»´åº¦å‹ç¼©ä¸º 128 ç»´
            nn.LeakyReLU()
        )

        # GCN å±‚
        self.gcn1 = GCNConv(128, 128)  # ä½¿ç”¨ GCNConv ä»£æ›¿ RGCNConv
        self.gcn2 = GCNConv(128, 128)  # ä½¿ç”¨ GCNConv ä»£æ›¿ RGCNConv

        # è¾“å‡ºå±‚
        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(128, 128),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(128, 2)  # äºŒåˆ†ç±»è¾“å‡º

    def forward(self, des, tweet, num_prop, cat_prop, new_feature, edge_index, edge_type):
        # å¤„ç†å„ä¸ªè¾“å…¥ç‰¹å¾
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)  # å¤„ç†æ–°ç‰¹å¾

        # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
        x = torch.cat((d, t, n, c, nf), dim=1)
        x = self.linear_relu_input(x)

        # ç¬¬ä¸€ä¸ª GCN å±‚
        x = self.gcn1(x, edge_index)
        x = F.dropout(x, p=self.dropout, training=self.training)

        # ç¬¬äºŒä¸ª GCN å±‚
        x = self.gcn2(x, edge_index)

        # è¾“å‡ºå±‚
        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)

        return x

    


class ESABotRGAT(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=1,
                 des_dim=28, tweet_dim=36, num_dim=12, cat_dim=40, new_dim=12, 
                 embedding_dimension=128, num_relations=2, num_heads=4, dropout=0.3):
        super(ESABotRGAT, self).__init__()
        self.dropout = dropout
        self.num_heads = num_heads

        # è¾“å…¥ç‰¹å¾çš„çº¿æ€§å˜æ¢ï¼ˆå¯è‡ªå®šä¹‰å‹ç¼©ç»´åº¦ï¼‰
        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, des_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, tweet_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, num_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, cat_dim),
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(
            nn.Linear(new_feature_size, new_dim),
            nn.LeakyReLU()
        )

        # æ€»ç‰¹å¾æ‹¼æ¥åçš„ç»´åº¦
        total_dim = des_dim + tweet_dim + num_dim + cat_dim + new_dim

        self.linear_relu_input = nn.Sequential(
            nn.Linear(total_dim, embedding_dimension),
            nn.LeakyReLU()
        )

        # R-GAT å›¾å·ç§¯å±‚
        self.rgat1 = RGATConv(
            embedding_dimension,
            embedding_dimension // num_heads,
            heads=num_heads,
            num_relations=num_relations
        )
        self.rgat2 = RGATConv(
            embedding_dimension,
            embedding_dimension,
            heads=1,
            num_relations=num_relations
        )

        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(embedding_dimension, embedding_dimension),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(embedding_dimension, 2)

    def forward(self, des, tweet, num_prop, cat_prop, new_feature, edge_index, edge_type):
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)

        # ç‰¹å¾æ‹¼æ¥
        x = torch.cat((d, t, n, c, nf), dim=1)
        x = self.linear_relu_input(x)

        # å›¾å·ç§¯ä¼ æ’­
        x = self.rgat1(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgat2(x, edge_index, edge_type)

        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)

        return x


import torch
import torch.nn as nn
import torch.nn.functional as F

class ESABotMLP(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=1, dropout=0.3):
        super(ESABotMLP, self).__init__()
        self.dropout = dropout

        # ğŸ‘‰ å„è‡ªå‹ç¼©ç»´åº¦æŒ‰ä½ çš„éœ€æ±‚è®¾ç½®
        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, 28),  # 32ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, 36),  # 52ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, 12),  # 12ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, 40),  # 20ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(  # æ–°å¢çš„ç‰¹å¾ 12ç»´
            nn.Linear(new_feature_size, 12),  # 12ç»´åº¦
            nn.LeakyReLU()
        )

        # ğŸ‘‡ æ€»ç»´åº¦æ”¹æˆ 128ï¼ˆ32 + 52 + 12 + 20 + 12ï¼‰
        self.linear_relu_input = nn.Sequential(
            nn.Linear(128, 128),  # é‡æ–°è°ƒæ•´æ€»è¾“å…¥ç»´åº¦ä¸º128
            nn.LeakyReLU()
        )

        # å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰éƒ¨åˆ†
        self.mlp1 = nn.Linear(128, 128)  # ç¬¬ä¸€å±‚å…¨è¿æ¥å±‚
        self.mlp2 = nn.Linear(128, 128)  # ç¬¬äºŒå±‚å…¨è¿æ¥å±‚
        self.mlp3 = nn.Linear(128, 2)    # è¾“å‡ºå±‚ï¼Œè¿›è¡ŒäºŒåˆ†ç±»

    def forward(self, des, tweet, num_prop, cat_prop, new_feature):
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)  # å¤„ç†æ–°ç‰¹å¾

        # æ‹¼æ¥æ—¶åŠ å…¥æ–°ç‰¹å¾ï¼Œæ³¨æ„æ–°çš„ç‰¹å¾ç»´åº¦
        x = torch.cat((d, t, n, c, nf), dim=1)
        x = self.linear_relu_input(x)

        # é€šè¿‡ MLP å±‚è¿›è¡Œå‰å‘ä¼ æ’­
        x = F.dropout(x, p=self.dropout, training=self.training)  # Dropout å±‚
        x = F.relu(self.mlp1(x))  # ç¬¬ä¸€å±‚å…¨è¿æ¥
        x = F.dropout(x, p=self.dropout, training=self.training)  # Dropout å±‚
        x = F.relu(self.mlp2(x))  # ç¬¬äºŒå±‚å…¨è¿æ¥
        x = self.mlp3(x)  # è¾“å‡ºå±‚

        return x


class ESABotRGCN_4layers(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=1, dropout=0.3):
        super(ESABotRGCN_4layers, self).__init__()
        self.dropout = dropout

        # å„è‡ªå‹ç¼©ç»´åº¦æŒ‰ä½ çš„éœ€æ±‚è®¾ç½®
        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, 28),  # 32ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, 36),  # 52ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, 12),  # 12ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, 40),  # 20ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(  # æ–°å¢çš„ç‰¹å¾ 12ç»´
            nn.Linear(new_feature_size, 12),  # 12ç»´åº¦
            nn.LeakyReLU()
        )

        # æ€»ç»´åº¦æ”¹æˆ 128ï¼ˆ32 + 52 + 12 + 20 + 12ï¼‰
        self.linear_relu_input = nn.Sequential(
            nn.Linear(128, 128),  # é‡æ–°è°ƒæ•´æ€»è¾“å…¥ç»´åº¦ä¸º128
            nn.LeakyReLU()
        )

        # å››ä¸ªå›¾å·ç§¯å±‚
        self.rgcn1 = RGCNConv(128, 128, num_relations=2)
        self.rgcn2 = RGCNConv(128, 128, num_relations=2)
        self.rgcn3 = RGCNConv(128, 128, num_relations=2)
        self.rgcn4 = RGCNConv(128, 128, num_relations=2)

        # è¾“å‡ºå±‚
        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(128, 128),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(128, 2)  # äºŒåˆ†ç±»

    def forward(self, des, tweet, num_prop, cat_prop, new_feature, edge_index, edge_type):
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)  # å¤„ç†æ–°ç‰¹å¾

        # æ‹¼æ¥æ—¶åŠ å…¥æ–°ç‰¹å¾ï¼Œæ³¨æ„æ–°çš„ç‰¹å¾ç»´åº¦
        x = torch.cat((d, t, n, c, nf), dim=1)
        x = self.linear_relu_input(x)

        # å››å±‚å›¾å·ç§¯
        x = self.rgcn1(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn2(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn3(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn4(x, edge_index, edge_type)
        
        # è¾“å‡ºå¤„ç†
        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)

        return x

class ESABotRGCN_3layers(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=1, dropout=0.3):
        super(ESABotRGCN_3layers, self).__init__()
        self.dropout = dropout

        # å„è‡ªå‹ç¼©ç»´åº¦æŒ‰ä½ çš„éœ€æ±‚è®¾ç½®
        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, 28),
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, 36),
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, 12),
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, 40),
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(
            nn.Linear(new_feature_size, 12),
            nn.LeakyReLU()
        )

        # æ€»ç»´åº¦æ”¹æˆ 128ï¼ˆ32 + 52 + 12 + 20 + 12ï¼‰
        self.linear_relu_input = nn.Sequential(
            nn.Linear(128, 128),
            nn.LeakyReLU()
        )

        # ä¸‰ä¸ªå›¾å·ç§¯å±‚
        self.rgcn1 = RGCNConv(128, 128, num_relations=2)
        self.rgcn2 = RGCNConv(128, 128, num_relations=2)
        self.rgcn3 = RGCNConv(128, 128, num_relations=2)

        # è¾“å‡ºå±‚
        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(128, 128),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(128, 2)  # äºŒåˆ†ç±»

    def forward(self, des, tweet, num_prop, cat_prop, new_feature, edge_index, edge_type):
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)

        # æ‹¼æ¥æ—¶åŠ å…¥æ–°ç‰¹å¾ï¼Œæ³¨æ„æ–°çš„ç‰¹å¾ç»´åº¦
        x = torch.cat((d, t, n, c, nf), dim=1)
        x = self.linear_relu_input(x)

        # ä¸‰å±‚å›¾å·ç§¯
        x = self.rgcn1(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn2(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn3(x, edge_index, edge_type)
        
        # è¾“å‡ºå¤„ç†
        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)

        return x

class ESABotRGCN_1layer(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=1, dropout=0.3):
        super(ESABotRGCN_1layer, self).__init__()
        self.dropout = dropout

        # å„è‡ªå‹ç¼©ç»´åº¦æŒ‰ä½ çš„éœ€æ±‚è®¾ç½®
        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, 28),
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, 36),
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, 12),
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, 40),
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(
            nn.Linear(new_feature_size, 12),
            nn.LeakyReLU()
        )

        # æ€»ç»´åº¦æ”¹æˆ 128ï¼ˆ32 + 52 + 12 + 20 + 12ï¼‰
        self.linear_relu_input = nn.Sequential(
            nn.Linear(128, 128),
            nn.LeakyReLU()
        )

        # å•å±‚å›¾å·ç§¯
        self.rgcn1 = RGCNConv(128, 128, num_relations=2)

        # è¾“å‡ºå±‚
        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(128, 128),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(128, 2)  # äºŒåˆ†ç±»

    def forward(self, des, tweet, num_prop, cat_prop, new_feature, edge_index, edge_type):
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)

        # æ‹¼æ¥æ—¶åŠ å…¥æ–°ç‰¹å¾ï¼Œæ³¨æ„æ–°çš„ç‰¹å¾ç»´åº¦
        x = torch.cat((d, t, n, c, nf), dim=1)
        x = self.linear_relu_input(x)

        # å•å±‚å›¾å·ç§¯
        x = self.rgcn1(x, edge_index, edge_type)

        # è¾“å‡ºå¤„ç†
        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)

        return x


class ESABotRGCN_5layers(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=1, dropout=0.3):
        super(ESABotRGCN_5layers, self).__init__()
        self.dropout = dropout

        # å„è‡ªå‹ç¼©ç»´åº¦æŒ‰ä½ çš„éœ€æ±‚è®¾ç½®
        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, 28),  # 32ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, 36),  # 52ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, 12),  # 12ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, 40),  # 20ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(  # æ–°å¢çš„ç‰¹å¾ 12ç»´
            nn.Linear(new_feature_size, 12),  # 12ç»´åº¦
            nn.LeakyReLU()
        )

        # æ€»ç»´åº¦æ”¹æˆ 128ï¼ˆ32 + 52 + 12 + 20 + 12ï¼‰
        self.linear_relu_input = nn.Sequential(
            nn.Linear(128, 128),  # é‡æ–°è°ƒæ•´æ€»è¾“å…¥ç»´åº¦ä¸º128
            nn.LeakyReLU()
        )

        # äº”ä¸ªå›¾å·ç§¯å±‚
        self.rgcn1 = RGCNConv(128, 128, num_relations=2)
        self.rgcn2 = RGCNConv(128, 128, num_relations=2)
        self.rgcn3 = RGCNConv(128, 128, num_relations=2)
        self.rgcn4 = RGCNConv(128, 128, num_relations=2)
        self.rgcn5 = RGCNConv(128, 128, num_relations=2)  # ç¬¬äº”å±‚

        # è¾“å‡ºå±‚
        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(128, 128),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(128, 2)  # äºŒåˆ†ç±»

    def forward(self, des, tweet, num_prop, cat_prop, new_feature, edge_index, edge_type):
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)  # å¤„ç†æ–°ç‰¹å¾

        # æ‹¼æ¥æ—¶åŠ å…¥æ–°ç‰¹å¾ï¼Œæ³¨æ„æ–°çš„ç‰¹å¾ç»´åº¦
        x = torch.cat((d, t, n, c, nf), dim=1)
        x = self.linear_relu_input(x)

        # äº”å±‚å›¾å·ç§¯
        x = self.rgcn1(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn2(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn3(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn4(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn5(x, edge_index, edge_type)

        # è¾“å‡ºå¤„ç†
        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)

        return x
class ESABotRGCN_8layers(nn.Module):
    def __init__(self, des_size=768, tweet_size=768, num_prop_size=7, cat_prop_size=11, new_feature_size=1, dropout=0.3):
        super(ESABotRGCN_8layers, self).__init__()
        self.dropout = dropout

        # å„è‡ªå‹ç¼©ç»´åº¦æŒ‰ä½ çš„éœ€æ±‚è®¾ç½®
        self.linear_relu_des = nn.Sequential(
            nn.Linear(des_size, 28),  # 32ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_tweet = nn.Sequential(
            nn.Linear(tweet_size, 36),  # 52ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_num_prop = nn.Sequential(
            nn.Linear(num_prop_size, 12),  # 12ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_cat_prop = nn.Sequential(
            nn.Linear(cat_prop_size, 40),  # 20ç»´åº¦
            nn.LeakyReLU()
        )
        self.linear_relu_new_feature = nn.Sequential(  # æ–°å¢çš„ç‰¹å¾ 12ç»´
            nn.Linear(new_feature_size, 12),  # 12ç»´åº¦
            nn.LeakyReLU()
        )

        # æ€»ç»´åº¦æ”¹æˆ 128ï¼ˆ32 + 52 + 12 + 20 + 12ï¼‰
        self.linear_relu_input = nn.Sequential(
            nn.Linear(128, 128),  # é‡æ–°è°ƒæ•´æ€»è¾“å…¥ç»´åº¦ä¸º128
            nn.LeakyReLU()
        )

        # å…«ä¸ªå›¾å·ç§¯å±‚
        self.rgcn1 = RGCNConv(128, 128, num_relations=2)
        self.rgcn2 = RGCNConv(128, 128, num_relations=2)
        self.rgcn3 = RGCNConv(128, 128, num_relations=2)
        self.rgcn4 = RGCNConv(128, 128, num_relations=2)
        self.rgcn5 = RGCNConv(128, 128, num_relations=2)
        self.rgcn6 = RGCNConv(128, 128, num_relations=2)
        self.rgcn7 = RGCNConv(128, 128, num_relations=2)
        self.rgcn8 = RGCNConv(128, 128, num_relations=2)  # ç¬¬å…«å±‚

        # è¾“å‡ºå±‚
        self.linear_relu_output1 = nn.Sequential(
            nn.Linear(128, 128),
            nn.LeakyReLU()
        )
        self.linear_output2 = nn.Linear(128, 2)  # äºŒåˆ†ç±»

    def forward(self, des, tweet, num_prop, cat_prop, new_feature, edge_index, edge_type):
        d = self.linear_relu_des(des)
        t = self.linear_relu_tweet(tweet)
        n = self.linear_relu_num_prop(num_prop)
        c = self.linear_relu_cat_prop(cat_prop)
        nf = self.linear_relu_new_feature(new_feature)  # å¤„ç†æ–°ç‰¹å¾

        # æ‹¼æ¥æ—¶åŠ å…¥æ–°ç‰¹å¾ï¼Œæ³¨æ„æ–°çš„ç‰¹å¾ç»´åº¦
        x = torch.cat((d, t, n, c, nf), dim=1)
        x = self.linear_relu_input(x)

        # å…«å±‚å›¾å·ç§¯
        x = self.rgcn1(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn2(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn3(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn4(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn5(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn6(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn7(x, edge_index, edge_type)
        x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.rgcn8(x, edge_index, edge_type)

        # è¾“å‡ºå¤„ç†
        x = self.linear_relu_output1(x)
        x = self.linear_output2(x)

        return x
